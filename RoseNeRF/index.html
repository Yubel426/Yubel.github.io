<!DOCTYPE html>
<html><head lang="en">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>RoseNeRF</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

    <!-- <link rel="apple-touch-icon" href="https://groups.csail.mit.edu/graphics/rendernet/apple-touch-icon.png"> -->
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="files/bootstrap.min.css">
    <link rel="stylesheet" href="files/font-awesome.min.css">
    <link rel="stylesheet" href="files/codemirror.min.css">
    <link rel="stylesheet" href="files/app.css">

    <link rel="stylesheet" href="files/bootstrap.min_002.css">

    <link href="dist/image-compare-viewer.min.css" rel="stylesheet">
    <!-- <style>
        .container {

            width: 100%;
        }
    </style> -->

    <script src="files/jquery.min.js"></script>
    <script src="files/bootstrap.min.js"></script>
    <script src="files/codemirror.min.js"></script>
    <script src="files/clipboard.min.js"></script>
    
    <script src="files/app.js"></script>
</head>



<body data-new-gr-c-s-check-loaded="8.904.0" data-gr-ext-installed="">
    <div class="container">
        <div class="row">
            <h1 class="col-md-12 text-center">
                Refracting Once is Enough: Neural Radiance Fields for
              <br>Novel-View Synthesis of Real Refractive Objects
              <!-- <br><small>SIGGRAPH Asia 2022 Technical Communications</small> -->
            </h1>
        </div>
        <div class="row">
            <div class="col-md-13 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://github.com/Yubel426">
                            Xiaoqian Liang
                        </a>
                        <!-- <br>Xi'an Jiaotong University -->
                    </li>
                    <li>
                        <a href="https://gr.xjtu.edu.cn/en/web/wangjianji">
                            Jianji Wang
                        </a>
                        <!-- <br>Xi'an Jiaotong University -->
                    </li>
                    <li>
                        <a href="">
                            Yuanliang Lu
                        </a>
                        <!-- <br>Xi'an Jiaotong University -->
                    </li>
                    <!-- <br> -->
                    <li>
                        <a href="">
                            Xubin Duan
                        </a>
                        <!-- <br>Xi'an Jiaotong University -->
                    </li>
                    <li>
                        <a href="">
                            Xichun Liu
                        </a>
                        <!-- <br>Xi'an Jiaotong University -->
                    </li>
                    <li>
                        <a href="https://gr.xjtu.edu.cn/en/web/nnzheng">
                            Nanning Zheng
                        </a>
                        <!-- <br>Xi'an Jiaotong University -->
                    </li>
                    <br>
                    Xi'an Jiaotong University
                <!-- </br> -->

                </ul>
            </div>
        </div>
        <div class="row">
            <div class="col-md-6 col-md-offset-3 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="" target="_blank">
                        <img src="assets/pdf.png" height="50px">
                            <h5><b>Paper(Coming soon)</b></h5>
                        </a>
                    </li>
                    <li>
                        <a href="https://vistec-my.sharepoint.com/:f:/g/personal/pakkapon_p_s19_vistec_ac_th/EnIUhsRVJOdNsZ_4smdhye0B8z0VlxqOR35IR3bp0uGupQ?e=TsaQgM" target="_blank">
                        <img src="assets/database.png" height="50px">
                            <h5><b>Shiny Dataset</b></h5>
                        </a>
                    </li>
                    <li>
                        <a href="https://drive.google.com/drive/folders/1Ys393lwzZ1feXnMMHG7FS-f_1aqDpx6l?usp=share_link" target="_blank">
                        <img src="assets/database.png" height="50px">
                            <h5><b>Eikonal Field Dataset</b></h5>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/Yubel426/RoseNeRF" target="_blank">
                        <img src="assets/github.png" height="50px">
                            <h5><b>Code</b></h5>
                        </a>
                    </li>
                </ul>
            </div>
        </div>
        <!-- <div class="row"> -->
        <!--     <div class="col&#45;md&#45;8 col&#45;md&#45;offset&#45;2 text&#45;center last"> -->
        <!--         <iframe align="center" width="560" height="315" src="https://www.youtube.com/embed/GAe0qKKQY_I" frameborder="0" allowfullscreen></iframe> -->
        <!--     </div> -->
        <!-- </div> -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
            </div>
        </div>
        <div class="row">
            <figure class="col-md-8 col-md-offset-2">
            <img src="assets/teaser.png" class="img-responsive" alt="overview">
                <figcaption>
                     <br>
                </figcaption>
            </figure>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <p class="text-justify">
                    Neural Radiance Fields (NeRF) have shown promise in novel view synthesis, but it still face challenges when applied to refractive objects.
                    The presence of refraction disrupts multiview consistency, often resulting in renderings that are either blurred or distorted.   
                    Recent methods alleviate this challenge by introducing external supervision, such as mask images and Index of Refraction.
                    However,acquiring such information is often impractical,limiting the application of NeRF-like models to complex scenes with refracting elementsand yielding unsatisfactory results.
                    To address these limitations, we introduce <b>RoseNeRF</b> (<b>R</b>efracting <b>o</b>nce i<b>s</b> <b>e</b>nough for <b>NeRF</b>),
                    a novel method that simplifies the complex  interaction of rays within objects to a single refraction event. 
                    We design the refraction network that efficiently maps a ray in the 4D light field to its refracted counterpart, better modeling curved ray paths.
                    Furthermore, we introduce a regularization strategy to ensure the reversibility of optical paths, which is anchored in physical world theorems.
                    To help it easier for the network to learn the highly view-dependent appearance of refractive objects, we also propose novel density decoding strategies.
                    Our method is designed for seamless integration into most NeRF-like frameworks and has demonstrated state-of-the-art performance without any additional information on both the Eikonal Fields' dataset and Shiny dataset.
                </p>
            </div>
        </div>
        
 
        <div class="container" id="custom-container">
            <div id="image-compare1">
                <img src="assets/nerfacto.jpg" alt="" />
                <img src="assets/rosenerf.png" alt="" />
            </div>
            <div id="image-compare2">
                <img src="assets/eikonalfield_wineglass.png" alt="" />
                <img src="assets/logs_mynerf_wineglass.png" alt="" />
            </div>
        </div>
        <script src="dist/image-compare-viewer.min.js"></script>
        <script>
            const element = document.getElementById("image-compare1");
    
            const viewer = new ImageCompare(element, { addCircle: true }).mount();
            const element2 = document.getElementById("image-compare2");
    
            const viewer2 = new ImageCompare(element2, { addCircle: true }).mount();
            // const element2 = document.getElementById("image-compare2");
    
            // const viewer2 = new ImageCompare(element2, {
            //     verticalMode: true,
            //     addCircle: true
            // }).mount();
        </script>
        <div class="container" id="custom-container">
            <div id="image-compare3">
                <img src="assets/logs_msnerf_256_cd.png" alt="" />
                <img src="assets/logs_mynerf_cd.png" alt="" />
            </div>
            <div id="image-compare4">
                <img src="assets/logs_msnerf_256_lab.png" alt="" />
                <img src="assets/logs_mynerf_lab.png" alt="" />
            </div>
        </div>
        <script src="dist/image-compare-viewer.min.js"></script>
        <script>
            const element3 = document.getElementById("image-compare3");
    
            const viewer3 = new ImageCompare(element3, { addCircle: true }).mount();
            const element4 = document.getElementById("image-compare4");
    
            const viewer4 = new ImageCompare(element4, { addCircle: true }).mount();
            // const element2 = document.getElementById("image-compare2");
    
            // const viewer2 = new ImageCompare(element2, {
            //     verticalMode: true,
            //     addCircle: true
            // }).mount();
        </script>
        


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                <!-- <h3 class="text&#45;center"> -->
                    Results
                </h3>
                <h4>
                    Shiny Dataset
                </h4>
                <figure>
                    <img src="assets/res_shiny.jpg" class="img-responsive" alt="overview" style="margin-bottom: 0.25em;">
                    <figcaption>
                        Qualitative results of RoseNeRF and comparison methods on CD, Seasoning and Lab.
                        <br>
                        Data provided by <a href="https://nex-mpi.github.io/" target="_blank"><i>NeX: Real-time View Synthesis with Neural Basis Expansion, CVPR 2021</i></a>
                    </figcaption>
                </figure>
                <figure>
                    <img src="assets/res_shiny_tab.jpg" class="img-responsive" alt="overview" style="margin-bottom: 0.25em;">
                    <figcaption>
                    </figcaption>
                </figure>

                <h4>
                    Eikonal Field Dataset
                </h4>
                <figure>
                    <img src="assets/res_eik.jpg" class="img-responsive" alt="overview" style="margin-bottom: 0.25em;">
                    <figcaption>
                        Qualitative results of RoseNeRF and comparison methods on Pen and WineGlass.
                        <br>
                        Data provided by <a href="https://eikonalfield.mpi-inf.mpg.de/" target="_blank"><i>Eikonal Fields for Refractive Novel-View Synthesis, SIGGRAPH 2022 (Conference Proceedings)</i></a>
                    </figcaption>
                </figure>
                <figure>
                    <img src="assets/res_eik_tab.jpg" class="img-responsive" alt="overview" style="margin-bottom: 0.25em;">
                    <figcaption>
                    </figcaption>
                </figure>

                <h4>
                    Ablation
                </h4>
                <figure>
                    <img src="assets/ablation.jpg" class="img-responsive" alt="overview" style="margin-bottom: 0.25em;">
                    <figcaption>
                        Qualitative results of <a href="https://zx-yin.github.io/msnerf/" target="_blank">MS-NeRF</a> 
                        and MS-NeRF with our decoder strategy on test set images from Ball, Glass, WineGlass and Lab.
                        <br>
                        <!-- Data provided by <a href="https://eikonalfield.mpi-inf.mpg.de/" target="_blank"><i>Eikonal Fields for Refractive Novel-View Synthesis, SIGGRAPH 2022 (Conference Proceedings)</i></a> -->
                    </figcaption>
                </figure>

            </div>
        </div>
        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
<textarea id="bibtex" class="form-control" readonly="readonly" style="display: none;">@inproceedings{pan2022sample,
    author = {Pan, Jen-I and Su, Jheng-Wei and Hsiao, Kai-Wen and Yen, Ting-Yu and Chu, Hung-Kuo},
    title = {Sampling Neural Radiance Fields for Refractive Objects},
    year = {2022},
    isbn = {9781450394659},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3550340.3564234},
    doi = {10.1145/3550340.3564234},
    booktitle = {SIGGRAPH Asia 2022 Technical Communications},
    articleno = {5},
    numpages = {4},
    keywords = {eikonal rendering, neural radiance fields},
    location = {Daegu, Republic of Korea},
    series = {SA '22 Technical Communications}
}
</textarea>
                </div>
            </div>
        </div> -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    The website template was borrowed from
                    <a href="https://groups.csail.mit.edu/graphics/rendernet/">Michaël Gharbi</a>
                    ,
                    <a href="https://jonbarron.info/mipnerf360/">Jonathan T. Barron</a>
                    and
                    <a href="https://nvlabs.github.io/instant-ngp/">Thomas Müller</a>
                    .
                </p>
            </div>
        </div>
    </div>


</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>